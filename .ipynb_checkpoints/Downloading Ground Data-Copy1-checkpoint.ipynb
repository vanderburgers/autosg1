{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6d1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#####  Modules  #####\n",
    "#####################\n",
    "\n",
    "# Arrays and handling data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from astropy.io import fits # Astronomical files\n",
    "\n",
    "# Plotting data\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plot\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Pulling data\n",
    "import requests\n",
    "import json\n",
    "from urllib.parse import quote as urlencode   \n",
    "\n",
    "import os # Accessing local files\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Creating apertures\n",
    "from photutils.aperture import EllipticalAperture\n",
    "from photutils.aperture import aperture_photometry\n",
    "from astropy.wcs import WCS # Converting between pixels and WCS\n",
    "\n",
    "from IPython.display import clear_output # Clearing output to not lag notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a0da6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07856742013183862\n"
     ]
    }
   ],
   "source": [
    "# Getting ra, dec and radius from TIC ID from the TIO Catalog\n",
    "\n",
    "tic_ID = \"TIC 120960812\" #\"TIC 155657581\" # SIMBAD4 flickers really brightly so it should be easy to spot\n",
    "\n",
    "ra = \"286.638\" #\"206.395293725348\"\n",
    "dec = \"39.4879\" #\"79.3967479665581\"\n",
    "cutout_size = \"200\" #\"600\" # Arcseconds\n",
    "\n",
    "radius = str(float(cutout_size) * float(math.sqrt(2)) / float(3600)) # Search radius. Cutout_size * root 2 / 2 for each side. Needs to be in decimal degrees 1/120 degrees\n",
    "print(radius)\n",
    "\n",
    "period = 0.3681414 #days\n",
    "\n",
    "skip_count = 0\n",
    "global skip_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2d9c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query using MAST to get the cone and all the stars inside the cone\n",
    "\n",
    "def mast_query(request):\n",
    "    request_url = \"https://mast.stsci.edu/api/v0/invoke\" # Base URL\n",
    "    \n",
    "    version = \".\".join(map(str, sys.version_info[:3])) # Grab Python version\n",
    "    \n",
    "    headers = { # Create HTTP header variables\n",
    "        \"Content-type\": \"application/x-www-form-urlencoded\",\n",
    "        \"Accept\": \"text/plain\",\n",
    "        \"User-agent\": \"python-requests/\" + str(version)\n",
    "    }\n",
    "    \n",
    "    # Encoding the request as a JSON string\n",
    "    req_string = json.dumps(request)\n",
    "    req_string = urlencode(req_string)\n",
    "    \n",
    "    response = requests.post(str(request_url), data = \"request=\" + str(req_string), headers = headers) # Perform the HTTP request\n",
    "    \n",
    "    # Pull out the headers and response content\n",
    "    head = response.headers # Content where head is the response HTTP headers\n",
    "    content = response.content.decode(\"utf-8\") # Returned data\n",
    "    return head, content\n",
    "\n",
    "def tic_advanced_search_position_rows():\n",
    "    request = {\"service\": \"Mast.Catalogs.Filtered.Tic.Position.Rows\",\n",
    "               \"format\": \"json\",\n",
    "               \"params\": {\n",
    "                   \"columns\": \"*\",\n",
    "                   \"filters\": [],\n",
    "                   \"ra\": float(ra),\n",
    "                   \"dec\": float(dec),\n",
    "                   \"radius\": float(radius)\n",
    "               }\n",
    "    }\n",
    "    \n",
    "    headers, out_string = mast_query(request)\n",
    "    out_data = json.loads(out_string)\n",
    "    dataframe = pd.DataFrame(out_data[\"data\"])\n",
    "    #with open(\"847_length_cone.pkl\", \"wb\") as my_file:\n",
    "    #    pickle.dump(dataframe, my_file)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f7a9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_everything(dictionary_key, brightness, time_of_frame, median, offset, TESS_magnitude, image_filter): # Name, brightness, time, median, offset, magnitude, filter\n",
    "    if dictionary_key in all_star_data.keys():\n",
    "        all_star_data[dictionary_key][\"brightness\"].append(brightness)\n",
    "        all_star_data[dictionary_key][\"time\"].append(time_of_frame)\n",
    "        all_star_data[dictionary_key][\"median\"].append(median)\n",
    "        all_star_data[dictionary_key][\"offset\"].append(offset)\n",
    "        all_star_data[dictionary_key][\"filter\"].append(image_filter)\n",
    "    else:\n",
    "        all_star_data[dictionary_key] = {\"brightness\": [brightness], \"time\": [time_of_frame], \"median\": [median], \"offset\": [offset], \"TESS_magnitude\": TESS_magnitude, \"filter\": [image_filter]}\n",
    "    \n",
    "    with open(\"FINAL_120960812_0-299.pkl\", \"wb\") as my_file:\n",
    "        pickle.dump(all_star_data, my_file)\n",
    "\n",
    "def get_brightness_and_offset(fits_image, px, py):\n",
    "    for subtraction_index in range(10, 0, -1): # Iterating backwards to get a smaller and smaller outer bounds\n",
    "        try:\n",
    "            mini_max_y, mini_max_x = np.unravel_index((fits_image[int(py)-subtraction_index:int(py)+subtraction_index, int(px)-subtraction_index:int(px)+subtraction_index]).argmax(), (fits_image[int(py)-subtraction_index:int(py)+subtraction_index, int(px)-subtraction_index:int(px)+subtraction_index]).shape) #fits_image.argmax(), fits_image.shape)\n",
    "            max_x = int(px + (mini_max_x - 10))\n",
    "            max_y = int(py + (mini_max_y - 10))\n",
    "            ####print(\"(\" + str(max_x) + \", \" + str(max_y) + \")\")\n",
    "            \n",
    "            testing_px = 0\n",
    "            testing_py = 0\n",
    "            while (max_x + testing_px) < len(fits_image[max_y]):\n",
    "                if fits_image[max_y][max_x + testing_px] > np.median(fits_image):\n",
    "                    testing_px += 1\n",
    "                else:\n",
    "                    break\n",
    "            while (max_y + testing_py) < len(fits_image):\n",
    "                if fits_image[max_y + testing_py][max_x] > np.median(fits_image):\n",
    "                    testing_py += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            positions = [(px, py)]\n",
    "            aperture = EllipticalAperture(positions, testing_px, testing_py, theta = 0.0)\n",
    "            phot_table = aperture_photometry(fits_image, aperture, method = \"exact\")\n",
    "            return float(phot_table[0][\"aperture_sum\"]), float(np.sqrt((max_x - px)**2 + (max_y - py)**2))\n",
    "            \n",
    "            break\n",
    "        except ValueError as e:\n",
    "            print(\"Too close to the edge to get brightness and offset ERROR here: \" + str(e))\n",
    "            if subtraction_index == 1:\n",
    "                return fits_image[int(py)][int(px)], 0\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "#def open_fits_file(target_w, fits_URL, mini_ra, mini_dec):\n",
    "def open_fits_file(fits_URL, mini_ra, mini_dec):\n",
    "    fits_file = fits.open(fits_URL) # fits can open URLS directly without needing to save the data as a .fits file\")\n",
    "    fits_image = np.array(fits_file[0].data)\n",
    "    fits_header = fits_file[0].header\n",
    "    target_w = WCS(fits_file[0].header)\n",
    "    target_px, target_py = target_w.wcs_world2pix(float(mini_ra), float(mini_dec), 1)\n",
    "    print(\"Target pixels: (\" + str(target_px) + \", \" + str(target_px) + \")\")\n",
    "    print(\"WCS: (\" + str(mini_ra) + \", \" + str(mini_dec) + \") \")\n",
    "    print(\"Picture size: \" + str(len(fits_image[0])) + \" by \" + str(len(fits_image)))\n",
    "    \n",
    "    target_brightness, target_offset = get_brightness_and_offset(fits_image, target_px, target_py)\n",
    "    print(\"Target brightness: \" + str(target_brightness))\n",
    "    add_everything(\"Target\", target_brightness, float(fits_header[\"OBSJD\"]), float(np.median(fits_image)), target_offset, cone.at[np.where(cone[\"ID\"] == int(tic_ID.split()[1]))[0][0], \"Tmag\"], fits_header[\"filter\"]) # Name, brightness, time, median, offset, magnitude, filter\n",
    "    \n",
    "    for star_from_cone_index in range(len(cone)):\n",
    "        print(\"Star: \" + str(star_from_cone_index))\n",
    "        star_from_cone_px, star_from_cone_py = target_w.wcs_world2pix(float(cone.at[star_from_cone_index, \"ra\"]), float(cone.at[star_from_cone_index, \"dec\"]), 1)\n",
    "        print(\"Star from cone pixels: (\" + str(star_from_cone_px) + \", \" + str(star_from_cone_py) + \")\")\n",
    "        \n",
    "        if (float(star_from_cone_px) < 0) or (float(star_from_cone_py) < 0) or (float(star_from_cone_px) > len(fits_image[0])) or (float(star_from_cone_py) > len(fits_image)):\n",
    "            print(\"Star \" + str(star_from_cone_index) + \" has to be skipped because it is not inside the cutout\")\n",
    "        else: # Star is in cutout\n",
    "            #skip_count = 0 # Needs to be in a row\n",
    "            \n",
    "            star_from_cone_brightness, star_from_cone_offset = get_brightness_and_offset(fits_image, star_from_cone_px, star_from_cone_py)\n",
    "            print(\"Star from cone brightness: \" + str(star_from_cone_brightness))\n",
    "            add_everything(str(star_from_cone_index), star_from_cone_brightness, float(fits_header[\"OBSJD\"]), float(np.median(fits_image)), star_from_cone_offset, cone.at[star_from_cone_index, \"Tmag\"], fits_header[\"filter\"]) # Name, brightness, time, median, offset, magnitude, filter\n",
    "            \n",
    "            '''\n",
    "            figure, ax = plot.subplots()\n",
    "            #ax.plot(px, py, \"or\")\n",
    "            #ax.plot(max_x, max_y, \"om\")\n",
    "            img = ax.imshow(fits_image, norm = matplotlib.colors.LogNorm()) # Log color scale to more easily see the contrast and see more stars. FLip the image data vertically to check with ds9\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size = \"5%\", pad = 0.05)\n",
    "            colorbar = figure.colorbar(img, cax = cax, orientation = \"vertical\")\n",
    "            colorbar.set_ticks([np.mean(fits_image), np.median(fits_image), 1000, 10000, np.max(fits_image), np.min(fits_image)])\n",
    "            colorbar.set_ticklabels([\"Mean: \" + str(np.mean(fits_image)), \"Median: \" + str(np.median(fits_image)), str(1000), str(10000), \"Max: \" + str(np.max(fits_image)), \"Min: \" + str(np.min(fits_image))])\n",
    "            #aperture_plot = matplotlib.patches.Ellipse((max_x, max_y), testing_px, testing_py, fill = False, color = \"pink\") #Circle((px, py), pixel_radius, color = \"r\", fill = False)\n",
    "            #ax.add_patch(aperture_plot)\n",
    "            ax.add_patch(matplotlib.patches.Circle((target_px, target_py), 7.5, fill = False, color = \"pink\"))\n",
    "            ax.add_patch(matplotlib.patches.Circle((star_from_cone_px, star_from_cone_py), 7.5, fill = False, color = \"orange\"))\n",
    "            plot.show()\n",
    "            '''\n",
    "        \n",
    "        #fits_file.close()\n",
    "        \n",
    "        #return float(phot_table[0][\"aperture_sum\"]), float(fits_header[\"OBSJD\"]), float(np.median(fits_image)), float(np.sqrt((max_x - px)**2 + (max_y - py)**2)), fits_header[\"filter\"]\n",
    "    fits_file.close()\n",
    "    print(\"..................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46bcb9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def get_ZTF_links(getting_target_w, star_number, mini_ra, mini_dec, cutout_size): # Download the ZTF image\n",
    "def get_ZTF_links(star_number, mini_ra, mini_dec, cutout_size): # Download the ZTF image\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    \n",
    "    metadata_URL = \"https://irsa.ipac.caltech.edu/ibe/search/ztf/products/sci?POS=\" + str(mini_ra) + \",\" + str(mini_dec)\n",
    "    metadata_response = requests.get(metadata_URL)\n",
    "    save_table_name = \"ogfile.txt\" # All different stars from cone\n",
    "    open(save_table_name, \"wb\").write(metadata_response.content)\n",
    "    \n",
    "    table = \"\"\n",
    "    with open(save_table_name) as saved_table_file:\n",
    "        lines = saved_table_file.readlines()\n",
    "        headers = lines[90].replace(\" \", \"\").split(\"|\")[1:-1]\n",
    "        headers.insert(19, \"obstime\") # Adding the times which are separated by spaces so pandas can use \" \" as a delimeter\n",
    "        headers.insert(45, \"ipac_pub_time\")\n",
    "        \n",
    "        table = pd.read_table(save_table_name, skiprows = 94, names = headers, delim_whitespace = True) # After row 94 is the data, but 91 is the header\n",
    "    \n",
    "    lightcurve_data = {\"brightness\": [], \"time\": [], \"median\": [], \"offset\": []}\n",
    "    w = 0\n",
    "    skip_count = 0\n",
    "    for picture_number in range(0, 300): #len(table)): # For each frame for the lightcurve of the same picture -- same star, different time\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        print(\"\\n\\n\\nStar \" + str(star_number) + \"   Frame \" + str(picture_number))\n",
    "        \n",
    "        file_fracday = str(table.at[picture_number, \"filefracday\"]) # yyyy + mm + dd + fracday\n",
    "        year = str(file_fracday[:4]) # yyyy\n",
    "        month = str(file_fracday[4:6]) # mm\n",
    "        day = str(file_fracday[6:8]) # dd\n",
    "        fracday = str(file_fracday[8:])\n",
    "        padded_field = str(\"000\" + str(table.at[picture_number, \"field\"])) # 000 + field\n",
    "        filter_code = str(table.at[picture_number, \"filtercode\"])\n",
    "        padded_ccdid = str(table.at[picture_number, \"ccdid\"]) # ccdid\n",
    "        image_type_code = str(table.at[picture_number, \"imgtypecode\"]) # imgtypecode\n",
    "        qid = str(table.at[picture_number, \"qid\"])\n",
    "        suffix = \"sciimg.fits\" # Primary science image\n",
    "        \n",
    "        fits_URL = \"https://irsa.ipac.caltech.edu/ibe/data/ztf/products/sci/\" + str(year) + \"/\" + str(month) + str(day) + \"/\" + str(fracday) + \"/ztf_\" + str(file_fracday) + \"_\" + str(padded_field) + \"_\" + str(filter_code) + \"_c\" + str(padded_ccdid) + \"_\" + str(image_type_code) + \"_q\" + str(qid) + \"_\" + str(suffix) # Entire .fits file\n",
    "        if not cutout_size == \"\":\n",
    "            fits_URL += \"?center=\" + str(ra) + \",\" + str(dec) + \"&size=\" + str(cutout_size) + \"arcsec&gzip=false\" # For downloading .fits cutout\n",
    "        print(fits_URL)\n",
    "        # Saving the .fits file\n",
    "        response = requests.get(str(fits_URL)) # I don't need the URL results because fits can open right from the URL\n",
    "        try:\n",
    "            open(\"SIMBAD4_Images/\" + str(star_number) + \"_3/ztf_\" + str(file_fracday) + \"_\" + str(padded_field) + \"_\" + str(filter_code) + \"_c\" + str(padded_ccdid) + \"_\" + str(image_type_code) + \"_q\" + str(qid) + \"_frame\" + str(picture_number) + \"_\" + str(suffix), \"wb\").write(response.content) # Save .fits file\n",
    "        except:\n",
    "            print(\"Couldn't save .fits file\")\n",
    "        \n",
    "        try:\n",
    "            open_fits_file(fits_URL, float(mini_ra), float(mini_dec))\n",
    "            #if getting_target_w:\n",
    "            #    print(\"getting target_w\")\n",
    "            #    target_w, brightness, time, median, offset, image_filter = open_target_w_fits_file(fits_URL, float(mini_ra), float(mini_dec))\n",
    "            #    lightcurve_data[\"brightness\"].append(brightness)\n",
    "            #    lightcurve_data[\"time\"].append(time)\n",
    "            #    lightcurve_data[\"median\"].append(median)\n",
    "            #    lightcurve_data[\"offset\"].append(offset)\n",
    "            #    lightcurve_data[\"filter\"].append(image_filter)\n",
    "            #    w = target_w\n",
    "            #    getting_target_w = False\n",
    "            #else:\n",
    "            #    #print(\"normal star using target_w\")\n",
    "            #    #with open(\"SIMBAD4_target_w.pkl\", \"rb\") as file:\n",
    "            #    #    loaded_w = pickle.load(file)\n",
    "            #    #    w = loaded_w\n",
    "            #    #brightness, time, median, offset, image_filter = open_fits_file(w, fits_URL, float(mini_ra), float(mini_dec))\n",
    "            #    brightness, time, median, offset, image_filter = open_fits_file(fits_URL, float(mini_ra), float(mini_dec))\n",
    "            #    lightcurve_data[\"brightness\"].append(brightness)\n",
    "            #    lightcurve_data[\"time\"].append(time)\n",
    "            #    lightcurve_data[\"median\"].append(median)\n",
    "            #    lightcurve_data[\"offset\"].append(offset)\n",
    "            #    lightcurve_data[\"filter\"] = image_filter\n",
    "            #open_fits_file(fits_URL, float(mini_ra), float(mini_dec))\n",
    "            #print(\"here\")\n",
    "        except ValueError as e:\n",
    "            print(\"Failed and skipped: \" + str(e))\n",
    "            skip_count += 1\n",
    "            if skip_count == 15: # If it breaks 10 times in a row, it probably isn't in the image\n",
    "                break\n",
    "    \n",
    "    #return fits_URLs\n",
    "    #return lightcurve_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc3f2139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Star 270   Frame 0\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSIMBAD4_Images/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(target_star_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m######lightcurve_data = get_ZTF_links(True, star_index, str(cone.at[star_index, \"ra\"]), str(cone.at[star_index, \"dec\"]), str(cutout_size))\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[43mget_ZTF_links\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_star_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mra\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcutout_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m'''star_index = 342\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03mif not os.path.exists(\"SIMBAD4_Images/\" + str(star_index) + \"_3\"):\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    os.makedirs(\"SIMBAD4_Images/\" + str(star_index) + \"_3\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    with open(str(star_index) + \"_3.pkl\", \"wb\") as my_file:\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m        pickle.dump(all_star_data, my_file)'''\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# INSIDE FOR LOOP -- like make a version of the function that uses the target w\u001b[39;00m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mget_ZTF_links\u001b[1;34m(star_number, mini_ra, mini_dec, cutout_size)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt save .fits file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[43mopen_fits_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfits_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmini_ra\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmini_dec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m#if getting_target_w:\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m#    print(\"getting target_w\")\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m#    target_w, brightness, time, median, offset, image_filter = open_target_w_fits_file(fits_URL, float(mini_ra), float(mini_dec))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m#open_fits_file(fits_URL, float(mini_ra), float(mini_dec))\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m#print(\"here\")\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mopen_fits_file\u001b[1;34m(fits_URL, mini_ra, mini_dec)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_fits_file\u001b[39m(fits_URL, mini_ra, mini_dec):\n\u001b[1;32m---> 52\u001b[0m     fits_file \u001b[38;5;241m=\u001b[39m \u001b[43mfits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfits_URL\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# fits can open URLS directly without needing to save the data as a .fits file\")\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     fits_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(fits_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m     54\u001b[0m     fits_header \u001b[38;5;241m=\u001b[39m fits_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mheader\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py:176\u001b[0m, in \u001b[0;36mfitsopen\u001b[1;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py:411\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[1;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\u001b[38;5;28mcls\u001b[39m, fileobj, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    401\u001b[0m              save_backup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lazy_load_hdus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    402\u001b[0m              ignore_missing_simple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py:1071\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[1;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[1;32m-> 1071\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\utils\\decorators.py:546\u001b[0m, in \u001b[0;36mdeprecated_renamed_argument.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        Use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malternative\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    544\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(msg, warning_type, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\io\\fits\\file.py:156\u001b[0m, in \u001b[0;36m_File.__init__\u001b[1;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Handle raw URLs\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    155\u001b[0m         mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mostream\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_url(fileobj)):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Handle responses from URL requests that have already been opened\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPResponse):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\utils\\data.py:1401\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(remote_url, cache, show_progress, timeout, sources, pkgname, http_headers, ssl_context, allow_insecure)\u001b[0m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sources listed and file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremote_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in cache! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1398\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease include primary URL in sources if you want it to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1399\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincluded as a valid source.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sources) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors[sources[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError(\n\u001b[0;32m   1404\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to open any source! Exceptions were \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m   1405\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merrors\u001b[39;00m[sources[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\utils\\data.py:1364\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(remote_url, cache, show_progress, timeout, sources, pkgname, http_headers, ssl_context, allow_insecure)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source_url \u001b[38;5;129;01min\u001b[39;00m sources:\n\u001b[0;32m   1363\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1364\u001b[0m         f_name \u001b[38;5;241m=\u001b[39m \u001b[43m_download_file_from_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m                \u001b[49m\u001b[43msource_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m                \u001b[49m\u001b[43mremote_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpkgname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpkgname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhttp_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m                \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallow_insecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_insecure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m         \u001b[38;5;66;03m# Success!\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\utils\\data.py:1168\u001b[0m, in \u001b[0;36m_download_file_from_source\u001b[1;34m(source_url, show_progress, timeout, remote_url, cache, pkgname, http_headers, ftp_tls, ssl_context, allow_insecure)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1168\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_try_url_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mftp_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mftp_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mallow_insecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_insecure\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m remote:\n\u001b[0;32m   1171\u001b[0m     info \u001b[38;5;241m=\u001b[39m remote\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\site-packages\\astropy\\utils\\data.py:1105\u001b[0m, in \u001b[0;36m_try_url_open\u001b[1;34m(source_url, timeout, http_headers, ftp_tls, ssl_context, allow_insecure)\u001b[0m\n\u001b[0;32m   1102\u001b[0m req \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(source_url, headers\u001b[38;5;241m=\u001b[39mhttp_headers)\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1107\u001b[0m     reason \u001b[38;5;241m=\u001b[39m exc\u001b[38;5;241m.\u001b[39mreason\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\urllib\\request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\urllib\\request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\urllib\\request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    568\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\urllib\\request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autosgenviro\\lib\\urllib\\request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "cone = tic_advanced_search_position_rows()\n",
    "global cone\n",
    "#open(\"cone2.txt\", \"w\").write(str(cone)) # Save the cone as a file because it is too large\n",
    "print(len(cone))\n",
    "\n",
    "all_star_data = {} #\"Target\": {\"brightness\": [], \"time\": [], \"median\": [], \"offset\": [], \"TESS_magnitude\": [], \"filter\": []}}\n",
    "\n",
    "#print(cone.loc[cone[\"ID\"] == 155657581]) # IS A NUMBER NOT STRING, whole row\n",
    "#print(np.where(cone[\"ID\"] == 155657581)[0][0]) # Actual row int\n",
    "print(np.where(cone[\"ID\"] == int(tic_ID.split()[1]))[0][0])\n",
    "#hi\n",
    "target_star_index = 270 #342 #int(np.where(cone[\"ID\"] == 155657581)[0][0]) #np.where(cone[\"ID\"] == int(tic_ID.split()[1]))[0][0])\n",
    "\n",
    "'''\n",
    "for star_index in range(102, 348): #range(len(cone)): # For each star in cone -- all different stars\n",
    "    if not os.path.exists(\"SIMBAD4_Images/\" + str(star_index)):\n",
    "        os.makedirs(\"SIMBAD4_Images/\" + str(star_index))\n",
    "    #fits_URLs = get_ZTF_links(str(cone.at[star_index, \"ra\"]), str(cone.at[star_index, \"dec\"]), str(cutout_size))\n",
    "    lightcurve_data = get_ZTF_links(star_index, str(cone.at[star_index, \"ra\"]), str(cone.at[star_index, \"dec\"]), str(cutout_size))\n",
    "    if len(lightcurve_data[\"brightness\"]) == 0:\n",
    "        print(\"Skipped\")\n",
    "    else:\n",
    "        all_star_data.append(lightcurve_data)\n",
    "        with open(\"ALL_STAR_DATA.pkl\", \"wb\") as my_file:\n",
    "            pickle.dump(all_star_data, my_file)\n",
    "'''\n",
    "\n",
    "#star_index = 342 # Would be in for loop\n",
    "# BEFOER FOR LOOP -- FIRST CHECK\n",
    "'''\n",
    "if not os.path.exists(\"SIMBAD4_Images/\" + str(np.where(cone[\"ID\"] == 155657581)[0][0]) + \"_2\"):\n",
    "    os.makedirs(\"SIMBAD4_Images/\" + str(np.where(cone[\"ID\"] == 155657581)[0][0]) + \"_2\")\n",
    "lightcurve_data = get_ZTF_links(True, np.where(cone[\"ID\"] == 155657581)[0][0], str(cone.at[np.where(cone[\"ID\"] == 155657581)[0][0], \"ra\"]), str(cone.at[np.where(cone[\"ID\"] == 155657581)[0][0], \"dec\"]), str(cutout_size))\n",
    "if len(lightcurve_data[\"brightness\"]) == 0:\n",
    "    print(\"Skipped\")\n",
    "else:\n",
    "    all_star_data.append(lightcurve_data)\n",
    "    with open(\"342_2.pkl\", \"wb\") as my_file:\n",
    "        pickle.dump(all_star_data, my_file)\n",
    "'''\n",
    "#'''\n",
    "print(\"Target star is at index \" + str(target_star_index))\n",
    "if not os.path.exists(\"SIMBAD4_Images/\" + str(target_star_index) + \"_3\"):\n",
    "    os.makedirs(\"SIMBAD4_Images/\" + str(target_star_index) + \"_3\")\n",
    "######lightcurve_data = get_ZTF_links(True, star_index, str(cone.at[star_index, \"ra\"]), str(cone.at[star_index, \"dec\"]), str(cutout_size))\n",
    "get_ZTF_links(target_star_index, str(ra), str(dec), str(cutout_size))\n",
    "\n",
    "'''star_index = 342\n",
    "if not os.path.exists(\"SIMBAD4_Images/\" + str(star_index) + \"_3\"):\n",
    "    os.makedirs(\"SIMBAD4_Images/\" + str(star_index) + \"_3\")\n",
    "######lightcurve_data = get_ZTF_links(True, star_index, str(cone.at[star_index, \"ra\"]), str(cone.at[star_index, \"dec\"]), str(cutout_size))\n",
    "lightcurve_data = get_ZTF_links(False, star_index, str(cone.at[star_index, \"ra\"]), str(cone.at[star_index, \"dec\"]), str(cutout_size))\n",
    "if len(lightcurve_data[\"brightness\"]) == 0:\n",
    "    print(\"Skipped\")\n",
    "else:\n",
    "    lightcurve_data[\"Tmag\"] = cone.at[star_index, \"Tmag\"]\n",
    "    all_star_data.append(lightcurve_data)\n",
    "    with open(str(star_index) + \"_3.pkl\", \"wb\") as my_file:\n",
    "        pickle.dump(all_star_data, my_file)'''\n",
    "# INSIDE FOR LOOP -- like make a version of the function that uses the target w\n",
    "'''\n",
    "for star_index in range(225, len(cone)): #300):\n",
    "    if not star_index == np.where(cone[\"ID\"] == int(tic_ID.split()[1]))[0][0]:\n",
    "        if not os.path.exists(\"SIMBAD4_Images/\" + str(star_index)):\n",
    "            os.makedirs(\"SIMBAD4_Images/\" + str(star_index))\n",
    "        lightcurve_data = get_ZTF_links(False, star_index, str(cone.at[star_index, \"ra\"]), str(cone.at[star_index, \"dec\"]), str(cutout_size))\n",
    "        if len(lightcurve_data[\"brightness\"]) == 0:\n",
    "            print(\"Skipped\")\n",
    "        else:\n",
    "            all_star_data.append(lightcurve_data) # cone magnitude!!\n",
    "            with open(\"SIMBAD4_Images/\" + str(star_index) + \"/\" + str(star_index) + \".pkl\", \"wb\") as my_file:\n",
    "                pickle.dump(all_star_data, my_file)\n",
    "    else:\n",
    "        print(\"lol should skip\")\n",
    "#'''\n",
    "\n",
    "#clear_output(wait = True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa5ab2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(cone.loc[cone[\"ID\"] == 155657581]) # IS A NUMBER NOT STRING, column 342\n",
    "#print(all_star_data)\n",
    "#print(len(all_star_data))\n",
    "#open(\"ALL_STAR_DATA\")\n",
    "print(cone.iloc[217])\n",
    "\n",
    "#with open('ALL_STAR_DATA.pkl', 'rb') as f:\n",
    "#    loaded_dict = pickle.load(f)\n",
    "#    print(len(loaded_dict))\n",
    "star_98 = {}\n",
    "with open(\"98.pkl\", \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    star_98 = loaded_dict\n",
    "star_103 = {}\n",
    "with open(\"103_2.pkl\", \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    star_103 = loaded_dict\n",
    "star_108 = {}\n",
    "with open(\"108_3.pkl\", \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    star_108 = loaded_dict\n",
    "SIMBAD4_star = {}\n",
    "with open(\"342_2.pkl\", \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    SIMBAD4_star = loaded_dict\n",
    "\n",
    "shortest_index = np.min([len(SIMBAD4_star[0][\"brightness\"]), len(star_108[0][\"brightness\"]), len(star_103[0][\"brightness\"])])\n",
    "figre, ax = plot.subplots()\n",
    "plot_times = [] #np.array(SIMBAD4_star[0][\"time\"]) % period\n",
    "plot_brightnesses = [] #SIMBAD4_star[0][\"brightness\"]\n",
    "#'''\n",
    "individual_star = star_103\n",
    "count = 0\n",
    "for time_index in range(len(SIMBAD4_star[0][\"brightness\"])):\n",
    "    if time_index < len(individual_star[0][\"brightness\"]):\n",
    "    #if (time_index < len(star_108[0][\"brightness\"])) and (time_index < len(star_103[0][\"brightness\"])):\n",
    "        if SIMBAD4_star[0][\"time\"][time_index] in individual_star[0][\"time\"]:\n",
    "        #if (SIMBAD4_star[0][\"time\"][time_index] in star_108[0][\"time\"]) and (SIMBAD4_star[0][\"time\"][time_index] in star_103[0][\"time\"]):\n",
    "            index_test = individual_star[0][\"time\"].index(SIMBAD4_star[0][\"time\"][time_index])\n",
    "            plot_times.append(SIMBAD4_star[0][\"time\"][time_index] % period)\n",
    "            plot_brightnesses.append((SIMBAD4_star[0][\"brightness\"][time_index]) / (individual_star[0][\"brightness\"][index_test])) # each reference star is added onto the denominator\n",
    "            #plot_brightnesses.append((SIMBAD4_star[0][\"brightness\"][time_index]) / ((star_103[0][\"brightness\"][time_index]) + (star_108[0][\"brightness\"][time_index])))\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "print(\"Skip count: \" + str(count))\n",
    "ax.plot(plot_times, plot_brightnesses, \".\")\n",
    "#ax.plot(star_98[0][\"time\"], star_98[0][\"brightness\"], \".\") #, color = \"r\") # blue\n",
    "#ax.plot(star_103[0][\"time\"], star_103[0][\"brightness\"], \".\") # orange\n",
    "#ax.plot(star_108[0][\"time\"], star_108[0][\"brightness\"], \".\") # green\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25673e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make an aperture of the images in the folder\n",
    "mini_ra = 205.951607576101 #205.975722065762\n",
    "mini_dec = 79.3823056910152 #79.4493271718068\n",
    "directory = \"SIMBAD4_Images/342\"\n",
    "for filename_index in range(2): #len(os.listdir(directory))):\n",
    "    print(\"\\n\\n\\n\" + str(filename_index) + \" of \" + str(len(os.listdir(directory))))\n",
    "    f = os.path.join(directory, os.listdir(directory)[filename_index])\n",
    "    if os.path.isfile(f): # Checking if it is a file\n",
    "        try:\n",
    "            fits_file = fits.open(f) #fits_URL) # fits can open URLS directly without needing to save the data as a .fits file\n",
    "            fits_image = np.array(fits_file[0].data)\n",
    "            w = WCS(fits_file[0].header)\n",
    "            px, py = w.wcs_world2pix(float(mini_ra), float(mini_dec), 1)\n",
    "            #print(fits_image.shape)\n",
    "            testing_px = 0\n",
    "            testing_py = 0\n",
    "            mini_max_y, mini_max_x = np.unravel_index((fits_image[int(py)-10:int(py)+10, int(px)-10:int(px)+10]).argmax(), (fits_image[int(py)-10:int(py)+10, int(px)-10:int(px)+10]).shape)\n",
    "            \n",
    "            #print(\"(\" + str(mini_max_x) + \", \" + str(mini_max_y) + \")\")\n",
    "            max_x = int(px + (mini_max_x - 10))\n",
    "            max_y = int(py + (mini_max_y - 10))\n",
    "            \n",
    "            print(\"(\" + str(max_x) + \", \" + str(max_y) + \")\")\n",
    "            while (max_x + testing_px) < len(fits_image[max_y]):\n",
    "                if fits_image[max_y][max_x + testing_px] > np.median(fits_image):\n",
    "                    testing_px += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            while (max_y + testing_py) < len(fits_image):\n",
    "                if fits_image[max_y + testing_py][max_x] > np.median(fits_image):\n",
    "                    testing_py += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            positions = [(px, py)]\n",
    "            aperture = EllipticalAperture(positions, testing_px, testing_py, theta = 0.0) #CircularAperture(positions, r = pixel_radius)\n",
    "            phot_table = aperture_photometry(fits_image, aperture, method = \"exact\")\n",
    "            print(phot_table[0][\"aperture_sum\"]) # THE BRIGHTNESS\n",
    "            all_star_data[0][\"brightness\"].append(float(phot_table[0][\"aperture_sum\"]))\n",
    "            all_star_data[0][\"time\"].append(float(fits_file[0].header[\"OBSJD\"]))\n",
    "            all_star_data[0][\"brightness\"].append(float(np.median(fits_image)))\n",
    "            all_star_data[0][\"offset\"].append(np.median(fits_image) * np.pi * testing_px * testing_py)\n",
    "            \n",
    "            \n",
    "            # Plotting\n",
    "            figure, ax = plot.subplots()\n",
    "            ax.plot(px, py, \"or\")\n",
    "            ax.plot(max_x, max_y, \"om\")\n",
    "            img = ax.imshow(fits_image, norm = matplotlib.colors.LogNorm()) # Log color scale to more easily see the contrast and see more stars. FLip the image data vertically to check with ds9\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size = \"5%\", pad = 0.05)\n",
    "            colorbar = figure.colorbar(img, cax = cax, orientation = \"vertical\")\n",
    "            colorbar.set_ticks([np.mean(fits_image), np.median(fits_image), 1000, 10000, np.max(fits_image), np.min(fits_image)])\n",
    "            colorbar.set_ticklabels([\"Mean: \" + str(np.mean(fits_image)), \"Median: \" + str(np.median(fits_image)), str(1000), str(10000), \"Max: \" + str(np.max(fits_image)), \"Min: \" + str(np.min(fits_image))])\n",
    "            aperture_plot = matplotlib.patches.Ellipse((max_x, max_y), testing_px, testing_py, fill = False, color = \"pink\")\n",
    "            ax.add_patch(aperture_plot)\n",
    "            a = 100\n",
    "            closeup_subarray = fits_image[int(py)-a:int(py)+a, int(px)-a:int(px)+a]\n",
    "            closeup_patch = matplotlib.patches.Rectangle((px-a, py-a), len(closeup_subarray[0]), len(closeup_subarray), fill = False, color = \"pink\")\n",
    "            ax.add_patch(closeup_patch)\n",
    "            plot.show()\n",
    "            \n",
    "            #plot.imshow(closeup_subarray)\n",
    "            figure, ax = plot.subplots()\n",
    "            img = ax.imshow(closeup_subarray, norm = matplotlib.colors.LogNorm())\n",
    "            colorbar = figure.colorbar(img, cax = cax, orientation = \"vertical\")\n",
    "            colorbar.set_ticks([np.mean(fits_image), np.median(fits_image), 1000, 10000, np.max(fits_image), np.min(fits_image)])\n",
    "            colorbar.set_ticklabels([\"Mean: \" + str(np.mean(fits_image)), \"Median: \" + str(np.median(fits_image)), str(1000), str(10000), \"Max: \" + str(np.max(fits_image)), \"Min: \" + str(np.min(fits_image))])\n",
    "            plot.show()\n",
    "            \n",
    "            fits_file.close()\n",
    "        except:\n",
    "            print(\"File \" + str(f) + \" couldn't be opened as a .fits file\")\n",
    "    else:\n",
    "        print(\"File \" + str(f) + \" couldn't be opened as a file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_108 = {}\n",
    "with open(\"108_3.pkl\", \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    star_108 = loaded_dict\n",
    "star_103 = {}\n",
    "with open(\"103_2.pkl\", \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    star_103 = loaded_dict\n",
    "\n",
    "longer_star = star_108\n",
    "shorter_star = star_103\n",
    "longer_star_brightnesses = []\n",
    "shorter_star_brightnesses = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "for time_index in range(len(longer_star[0][\"brightness\"])):\n",
    "    if time_index < len(shorter_star[0][\"brightness\"]):\n",
    "    #if (time_index < len(star_108[0][\"brightness\"])) and (time_index < len(star_103[0][\"brightness\"])):\n",
    "        if longer_star[0][\"time\"][time_index] in shorter_star[0][\"time\"]:\n",
    "            index_test = shorter_star[0][\"time\"].index(longer_star[0][\"time\"][time_index])\n",
    "            longer_star_brightnesses.append(longer_star[0][\"brightness\"][time_index])\n",
    "            shorter_star_brightnesses.append(shorter_star[0][\"brightness\"][index_test])\n",
    "            #plot_brightnesses.append((SIMBAD4_star[0][\"brightness\"][time_index]) / ((star_103[0][\"brightness\"][time_index]) + (star_108[0][\"brightness\"][time_index])))\n",
    "        else:\n",
    "            count += 1\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "print(\"Skip count: \" + str(count))\n",
    "figre, ax = plot.subplots()\n",
    "ax.plot(longer_star_brightnesses, shorter_star_brightnesses, \".\")\n",
    "#ax.plot(star_98[0][\"time\"], star_98[0][\"brightness\"], \".\") #, color = \"r\") # blue\n",
    "#ax.plot(star_103[0][\"time\"], star_103[0][\"brightness\"], \".\") # orange\n",
    "#ax.plot(star_108[0][\"time\"], star_108[0][\"brightness\"], \".\") # green\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Brightness Reference star 108 TIC 155656210\")\n",
    "ax.set_ylabel(\"Brightness Reference star 103 TIC 155656195\")\n",
    "#plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_differences = []\n",
    "\n",
    "for time_index in range(len(longer_star[0][\"brightness\"])):\n",
    "    if time_index < len(shorter_star[0][\"brightness\"]):\n",
    "        if longer_star[0][\"time\"][time_index] in shorter_star[0][\"time\"]:\n",
    "            index_test = shorter_star[0][\"time\"].index(longer_star[0][\"time\"][time_index])\n",
    "            print(str(longer_star[0][\"time\"][time_index]) + \"   \" + str(shorter_star[0][\"time\"][index_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f963b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"FINAL_0-299.pkl\", \"rb\") as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "    print(len(loaded_dict))\n",
    "    print(len(loaded_dict[\"Target\"][\"brightness\"]))\n",
    "    print(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://fallingstar-data.com/forcedphot\"\n",
    "%run Passwords.ipynb\n",
    "\n",
    "response = requests.post(url = str(base_url) + \"/api-token-auth/\", data = {\"username\": username, \"password\": password})\n",
    "ra = 44\n",
    "dec = 22\n",
    "task_url = \"\"\n",
    "\n",
    "if response.status_code == 200:\n",
    "    token = response.json()[\"token\"]\n",
    "    print(\"Token: \" + str(token))\n",
    "    headers = {\"Authorization\": \"Token \" + str(token), \"Accept\": \"application/json\"}\n",
    "    \n",
    "    task_url = None\n",
    "    while not task_url:\n",
    "        with requests.Session() as session:\n",
    "            response = session.post(str(base_url) + \"/queue/\", headers = headers, data = {\"ra\": ra, \"dec\": dec, \"mjd_min\": 59248., \"send_email\": False})\n",
    "            \n",
    "            if response.status_code == 201:  # Successfull!\n",
    "                task_url = response.json()[\"url\"]\n",
    "                print(\"Task URL: \" + str(task_url))\n",
    "                \n",
    "                response = requests.get(task_url, allow_redirects = True)\n",
    "                open(\"test.txt\", \"wb\").write(response.content)\n",
    "            elif response.status_code == 429:  # Wait\n",
    "                message = response.json()[\"detail\"]\n",
    "                print(\"ERROR: \" + str(response.status_code))\n",
    "                print(response.json())\n",
    "                seconds = re.findall(r'available in (\\d+) seconds', message)\n",
    "                minutes = re.findall(r'available in (\\d+) minutes', message)\n",
    "                wait_time = 0\n",
    "                if t_sec:\n",
    "                    wait_time = int(seconds[0])\n",
    "                elif t_min:\n",
    "                    wait_time = int(minutes[0]) * 60\n",
    "                else:\n",
    "                    wait_time = 10\n",
    "                print(\"Waiting \" + str(wait_time) + \" seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else: # Fail\n",
    "                print(\"ERROR: \" + str(response.status_code))\n",
    "                print(response.json())\n",
    "                sys.exit()\n",
    "else:\n",
    "    print(\"ERROR: \" + str(response.status_code))\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b374b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_url = None\n",
    "while not result_url:\n",
    "    with requests.Session() as session:\n",
    "        response = session.get(task_url, headers = headers)\n",
    "        \n",
    "        if response.status_code == 200: # HTTP OK\n",
    "            if response.json()[\"finishtimestamp\"]:\n",
    "                result_url = response.json()[\"result_url\"]\n",
    "                print(\"Result URL: \" + str(result_url))\n",
    "                break\n",
    "            elif response.json()[\"starttimestamp\"]:\n",
    "                print(\"Task is running (started at \" + str(response.json()[\"starttimestamp\"]))\n",
    "            else:\n",
    "                print(\"Waiting 10 seconds...\")\n",
    "                time.sleep(10)\n",
    "        else:\n",
    "            print(\"ERROR: \" + str(response.status_code))\n",
    "            print(response.json())\n",
    "            sys.exit()\n",
    "\n",
    "\n",
    "panda_result = \"\"\n",
    "\n",
    "with requests.Session() as session:\n",
    "    textdata = session.get(result_url, headers = headers).text\n",
    "    #print(textdata)\n",
    "    \n",
    "    session.delete(task_url, headers = headers).json() # De-clutter sessions\n",
    "    \n",
    "    panda_result = pd.read_csv(io.StringIO(textdata.replace(\"###\", \"\")), delim_whitespace = True)\n",
    "    print(panda_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
